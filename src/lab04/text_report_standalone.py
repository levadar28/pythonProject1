#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.
"""

import sys
from pathlib import Path
import csv
import re
from collections import Counter


def read_text_with_encodings(path: str | Path) -> str:
    """
    –ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª, –ø—Ä–æ–±—É—è —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏.
    """
    p = Path(path)

    if not p.exists():
        raise FileNotFoundError(f"–§–∞–π–ª {p} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    # –°–ø–∏—Å–æ–∫ –∫–æ–¥–∏—Ä–æ–≤–æ–∫ –¥–ª—è –ø–æ–ø—ã—Ç–∫–∏ (–≤ –ø–æ—Ä—è–¥–∫–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)
    encodings_to_try = [
        'utf-8',
        'utf-16',
        'utf-16-le',
        'utf-16-be',
        'cp1251',
        'windows-1251',
        'cp866',
        'koi8-r',
        'iso-8859-1',
        'iso-8859-5'
    ]

    for encoding in encodings_to_try:
        try:
            content = p.read_text(encoding=encoding)
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω–æ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π: {encoding}")
            return content
        except UnicodeDecodeError:
            continue

    # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –Ω–µ –ø–æ–¥–æ—à–ª–∞, –ø—Ä–æ–±—É–µ–º —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫
    try:
        content = p.read_text(encoding='utf-8', errors='ignore')
        print("‚ö†Ô∏è  –§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫ –∫–æ–¥–∏—Ä–æ–≤–∫–∏")
        return content
    except Exception as e:
        raise UnicodeDecodeError(
            f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±–æ–≤–∞–Ω—ã –∫–æ–¥–∏—Ä–æ–≤–∫–∏: {', '.join(encodings_to_try)}") from e


def write_csv(rows: list[tuple], path: str | Path, header: tuple = None) -> None:
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ CSV"""
    p = Path(path)
    p.parent.mkdir(parents=True, exist_ok=True)

    with p.open("w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if header:
            writer.writerow(header)
        writer.writerows(rows)


def normalize(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç: casefold + —ë‚Üí–µ"""
    text = text.lower()
    text = text.replace('—ë', '–µ')
    return ' '.join(text.split())


def tokenize(text: str) -> list[str]:
    """–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç: \w+(?:-\w+)*"""
    return re.findall(r'\w+(?:-\w+)*', text)


def create_test_file():
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–µ UTF-8"""
    test_file = Path("data/input.txt")
    test_file.parent.mkdir(exist_ok=True)

    test_content = "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!"
    test_file.write_text(test_content, encoding="utf-8")
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {test_file}")
    print(f"üìù –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: '{test_content}'")

    return test_content


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

    print("üîç –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê")
    print("=" * 50)

    input_file = Path("data/input.txt")
    output_file = Path("data/report.csv")

    # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç - —Å–æ–∑–¥–∞–µ–º –µ–≥–æ
    if not input_file.exists():
        print("üìù –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª...")
        create_test_file()
    else:
        print(f"üìÅ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {input_file}")

    try:
        # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        print(f"üìñ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞...")
        text = read_text_with_encodings(input_file)

        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
        print("üîç –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞...")
        normalized = normalize(text)
        tokens = tokenize(normalized)
        freq = Counter(tokens)
        sorted_words = sorted(freq.items(), key=lambda x: (-x[1], x[0]))

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        if freq:
            write_csv(sorted_words, output_file, header=("word", "count"))
            print(f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        else:
            write_csv([], output_file, header=("word", "count"))
            print("üíæ –°–æ–∑–¥–∞–Ω –æ—Ç—á–µ—Ç —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º (—Ñ–∞–π–ª –ø—É—Å—Ç–æ–π)")

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤
        print(f"\n–í—Å–µ–≥–æ —Å–ª–æ–≤: {sum(freq.values())}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq)}")

        if freq:
            print("–¢–æ–ø-5:")
            for word, count in sorted_words[:5]:
                print(f"{word}:{count}")

        print("=" * 50)
        print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ CSV
        if output_file.exists():
            print(f"\nüìÑ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ {output_file}:")
            print(output_file.read_text(encoding="utf-8"))

    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)
    except UnicodeDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏: {e}")
        print("\nüí° –†–µ—à–µ–Ω–∏–µ: –£–¥–∞–ª–∏—Ç–µ —Ñ–∞–π–ª data/input.txt –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()